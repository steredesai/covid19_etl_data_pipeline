# -*- coding: utf-8 -*-
"""etl_pipeline.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DvsjQtDcVyfKM_IR6CqNjb7Iv63WY4bw
"""



import pandas as pd

# Step 1: Extract
def extract_data(file_path):
    print("🔍 Extracting data...")
    df = pd.read_csv(file_path)
    print(f"✅ Extracted {df.shape[0]} rows and {df.shape[1]} columns.")
    return df

# Step 2: Transform
def transform_data(df):
    print("🔧 Transforming data...")
    # Drop rows with missing country or date
    df = df.dropna(subset=["location", "date"])

    # Convert date to datetime
    df["date"] = pd.to_datetime(df["date"])

    # Fill missing numeric values with 0
    numeric_cols = df.select_dtypes(include='number').columns
    df[numeric_cols] = df[numeric_cols].fillna(0)

    print("✅ Transformation complete.")
    return df

# Step 3: Load
def load_data(df, output_path):
    print("📦 Loading data...")
    df.to_csv(output_path, index=False)
    print(f"✅ Data saved to {output_path}")

# Main
if __name__ == "__main__":
    input_file = "covid19_raw_data.csv"          # Replace with actual file name
    output_file = "covid19_cleaned_data.csv"

    df_raw = extract_data(input_file)
    df_clean = transform_data(df_raw)
    load_data(df_clean, output_file)